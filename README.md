# Sentiment-Analysis-of-Amazon-Kindle-Reviews-

![sentimentanalysis](https://user-images.githubusercontent.com/49653689/94883213-10b66280-0438-11eb-9eda-f0288f6f91ed.png)

#### -- Project Status: [Completed]

## Project Objective
The purpose of this project is to 

### Methods Used
* NLP-based Data Preprocessing 
* Word Vectorization (BoW, TF-IDF, and One-Hot Encoding) => Classifiers (SVM, MultinomialNB and Artificial Neural Network)
* Deployed Transfer Learning: LSTM & GRU with GloVe embedding
* Fine-tuned BERT language model

### Technologies

* jupyter, Python 3
* Pandas, Numpy, NLTK, Scikit-learn, TensorFlow, keras, PyTorch, seaborn, matplotlib

## Project Description

### Data 

A small subset of product reviews in [Amazon reviews: Kindle Store Category](https://www.kaggle.com/bharadwaj6/kindle-reviews/notebooks) obtained from [Amazon Review Data (2018)](https://nijianmo.github.io/amazon/index.html).

### Data Pre-processing

### Work Flow

### Results

*
*
*
*
*

## Futrue Work

## Reference

Understanding NLP Word Embeddings — Text Vectorization 
https://towardsdatascience.com/understanding-nlp-word-embeddings-text-vectorization-1a23744f7223

Natural Language Processing: From Basics to using RNN and LSTM 
https://towardsdatascience.com/natural-language-processing-from-basics-to-using-rnn-and-lstm-ef6779e4ae66

Word Embedding Explained, a comparison and code tutorial 
https://medium.com/@dcameronsteinke/tf-idf-vs-word-embedding-a-comparison-and-code-tutorial-5ba341379ab0

Understanding Word Embeddings with TF-IDF and GloVe 
https://towardsdatascience.com/understanding-word-embeddings-with-tf-idf-and-glove-8acb63892032

Illustrated Guide to LSTM’s and GRU’s: A step by step explanation 
https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21

Simple LSTM for text classification 
https://www.kaggle.com/kredy10/simple-lstm-for-text-classification

NLP using GloVe Embeddings 
https://www.kaggle.com/madz2000/nlp-using-glove-embeddings-99-87-accuracy

Transfer Learning for NLP: Fine-Tuning BERT for Text Classification
https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/

Multi Class Text Classification With Deep Learning Using BERT
https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613

A Visual Guide to Using BERT for the First Time
http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/

Tokenizers: How machines read 
https://blog.floydhub.com/tokenization-nlp/

3 subword algorithms help to improve your NLP model performance
https://medium.com/@makcedward/how-subword-helps-on-your-nlp-model-83dd1b836f46

Text preprocessing for BERT
https://www.kaggle.com/c/google-quest-challenge/discussion/127881

The Illustrated Transformer
http://jalammar.github.io/illustrated-transformer/

BERT Fine-Tuning Sentence Classification
https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=nSU7yERLP_66

BERT Explained – A list of Frequently Asked Questions
https://yashuseth.blog/2019/06/12/bert-explained-faqs-understand-bert-working/

