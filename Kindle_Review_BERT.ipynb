{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kindle_Review_BERT_3Class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxkDC/CZ8OGltDgAk4+mfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0b36c7e78b149ae822ee06c65146013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66156bb2ea09495bab86bcea5aa89d06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a25defaa7b3748eb93fabd045733c4d6",
              "IPY_MODEL_2cdf74002dc6458da2a73fdc9715919a"
            ]
          }
        },
        "66156bb2ea09495bab86bcea5aa89d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a25defaa7b3748eb93fabd045733c4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2210038ae60341ad9f153856414aa0b9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64b144131586455e83fb7be2a3b81a34"
          }
        },
        "2cdf74002dc6458da2a73fdc9715919a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3557014b1cbe4e4d801cde2527fd1240",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 587kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6ce8118e78044d592a11e6b0dd328b9"
          }
        },
        "2210038ae60341ad9f153856414aa0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64b144131586455e83fb7be2a3b81a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3557014b1cbe4e4d801cde2527fd1240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6ce8118e78044d592a11e6b0dd328b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa43b4de9aaa44229ee488a969aece23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_168e913bce044bd283542df0714290b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9eb4553b14144ec389304658ba2749c2",
              "IPY_MODEL_e7ccf7e1035f450dbf4a6e959354bb3f"
            ]
          }
        },
        "168e913bce044bd283542df0714290b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9eb4553b14144ec389304658ba2749c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae1e6d0c3d18479ea17eb678054f7b0d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d6cf496c2654dab8646ba27d6c5a1dd"
          }
        },
        "e7ccf7e1035f450dbf4a6e959354bb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33d8db7e47f346938e65d2c22fe06473",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:51&lt;00:00, 8.37B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff4acbb004a84a08a7b2f5fcfebdfeae"
          }
        },
        "ae1e6d0c3d18479ea17eb678054f7b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d6cf496c2654dab8646ba27d6c5a1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33d8db7e47f346938e65d2c22fe06473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff4acbb004a84a08a7b2f5fcfebdfeae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63ea1e647b89438eafa0dd19f94c34e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3de1d31cfa09476fb05f4610df94339f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_04dca8ef74ae4088b131478584777cf7",
              "IPY_MODEL_fb74a3939ab04f049010ea034583ad44"
            ]
          }
        },
        "3de1d31cfa09476fb05f4610df94339f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04dca8ef74ae4088b131478584777cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f3cd2d2b04e47fdac16cdc202dc6a79",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e70a7aecd0984a969c43a24639829d92"
          }
        },
        "fb74a3939ab04f049010ea034583ad44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76e2cbeddd1c4e6481881651f44ca8b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:17&lt;00:00, 25.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b3f128a2c894578b7ad977ff9c01541"
          }
        },
        "0f3cd2d2b04e47fdac16cdc202dc6a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e70a7aecd0984a969c43a24639829d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e2cbeddd1c4e6481881651f44ca8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b3f128a2c894578b7ad977ff9c01541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliviaxyl/Sentiment-Analysis-of-Amazon-Kindle-Reviews-/blob/master/Kindle_Review_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxOjIGj65mI",
        "outputId": "bb3f9faf-9763-47a5-b945-99faccec9167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Runtime ==> Change runtime type ==> Hardware accelerator ==> GPU\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsO2hXvT7qDt",
        "outputId": "e8c4bcd3-ba9f-46e2-86e8-28cb42c8685b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adic4cIK7qI0",
        "outputId": "3abe0fa6-ce3d-41a6-ddd5-ec7921766724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 542kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 552kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 563kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 573kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 583kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 593kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 604kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 614kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 624kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 634kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 645kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 655kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 675kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 686kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 696kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 706kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 716kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 727kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 737kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 747kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 757kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 768kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 778kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 788kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 798kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 808kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 819kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 829kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 839kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 849kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 860kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 870kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 880kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 890kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 901kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 911kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 921kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 931kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 942kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 952kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 962kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 972kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 983kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 993kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 57.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5fd43af5b7f24095674b5c62f2683abb3ff9ecdc63e3e497cff4f27ef296b6e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9GsICxq7uq6",
        "outputId": "4cbf2b88-df88-4196-f852-36035a817a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igOb17Pn7utK"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Kindle Reviews/kindle_reviews.csv')# Drop missing review "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXTXULjD7uxM",
        "outputId": "ed2715a9-7e54-4342-eb9c-19d4508daa69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df.dropna(subset=['reviewText'], inplace=True)\n",
        "df = df.sample(frac=.05, random_state=999).reset_index()\n",
        "df = df[['reviewText','summary','overall']]\n",
        "df['reviewText'] = df['reviewText'] + df['summary']\n",
        "df.drop('summary', axis=1, inplace=True)\n",
        "\n",
        "df['overall'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    28583\n",
              "4    12826\n",
              "3     4859\n",
              "2     1682\n",
              "1     1180\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA4kjIL77qHY"
      },
      "source": [
        "# 3 classes - Negative, Neutral, Positive\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# convert ratings to sentiments\n",
        "def rating_to_sentiment(reviews):\n",
        "    reviews['sentiment'] = \"\"\n",
        "    for i in range(len(reviews)):\n",
        "        if (reviews['overall'][i] == 1 or reviews['overall'][i] == 2):\n",
        "            reviews['sentiment'][i] = 'Negative'\n",
        "        elif (reviews['overall'][i] == 3):\n",
        "            reviews['sentiment'][i] = 'Neutral'\n",
        "        else:\n",
        "            reviews['sentiment'][i] = 'Positive'\n",
        "    return reviews\n",
        "            \n",
        "# under-sampling \n",
        "def under_sampling(reviews):\n",
        "    negative = len(reviews[reviews['sentiment'] == 'Negative'])\n",
        "    under_sample_indices = reviews[reviews.sentiment == 'Negative'].index\n",
        "    random1 = np.random.choice(reviews[reviews.sentiment == 'Neutral'].index, negative, replace=False)\n",
        "    random2 = np.random.choice(reviews[reviews.sentiment == 'Positive'].index, negative, replace=False)\n",
        "    under_sample_indices = np.concatenate([under_sample_indices, random1, random2])\n",
        "    reviews_under_sample = reviews.loc[under_sample_indices].reset_index(drop=True)\n",
        "    reviews_under_sample.drop('overall',axis=1, inplace=True)\n",
        "    return reviews_under_sample\n",
        "\n",
        "def balanced_classification(reviews):\n",
        "    reviews = rating_to_sentiment(reviews)\n",
        "    reviews_under_sample = under_sampling(reviews)\n",
        "    return reviews_under_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIoupR3P71Qk",
        "outputId": "9febb2d3-99d8-4ead-fd66-3f8e710fa965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "reviews_under_sample = balanced_classification(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0E3OB2p71S4",
        "outputId": "0d8ac0bc-e603-4d6c-b033-5b85cf4804aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reviews_under_sample['sentiment'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Negative', 'Neutral', 'Positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ALgEMbX71WQ"
      },
      "source": [
        "def number_of_class(reviews_under_sample, k):\n",
        "  # 3 classes - Negative, Neutral, Positive\n",
        "  if k == 3:\n",
        "    reviews_under_sample.replace({'Negative':0,'Neutral':1,'Positive':2},inplace=True)\n",
        "    reviews_under_sample = reviews_under_sample.sample(frac=1, random_state = 233).reset_index(drop=True)\n",
        "  elif k == 2:\n",
        "    # 2 classes - Negative, Positive\n",
        "    reviews_under_sample = reviews_under_sample.drop(reviews_under_sample[reviews_under_sample['sentiment']=='Neutral'].index, axis=0)\n",
        "    reviews_under_sample.replace({'Negative':0,'Positive':1},inplace=True)\n",
        "    reviews_under_sample = reviews_under_sample.sample(frac=1, random_state = 233).reset_index(drop=True)\n",
        "  else:\n",
        "    print('Error : --- Group Input Should Be In (2,3) ---')\n",
        "\n",
        "  # Get the lists of sentences and their labels.\n",
        "  sentences = reviews_under_sample.reviewText.values\n",
        "  labels = reviews_under_sample.sentiment.values\n",
        "\n",
        "  return sentences, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnWTOxJ39Drg"
      },
      "source": [
        "sentences, labels = number_of_class(reviews_under_sample,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFmgTq189GoW",
        "outputId": "bc154155-1d0c-4f01-a83d-be94fa6e368f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "e0b36c7e78b149ae822ee06c65146013",
            "66156bb2ea09495bab86bcea5aa89d06",
            "a25defaa7b3748eb93fabd045733c4d6",
            "2cdf74002dc6458da2a73fdc9715919a",
            "2210038ae60341ad9f153856414aa0b9",
            "64b144131586455e83fb7be2a3b81a34",
            "3557014b1cbe4e4d801cde2527fd1240",
            "e6ce8118e78044d592a11e6b0dd328b9"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0b36c7e78b149ae822ee06c65146013",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SASgWRay9GrX",
        "outputId": "50f4e196-7720-4892-8679-d85eb27b1b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  I enjoyed this short(very  short)story. Just as you were getting into it,it ended . A little more mystery and another murder would have been great . All in all a great readThe Island Murder\n",
            "Tokenized:  ['i', 'enjoyed', 'this', 'short', '(', 'very', 'short', ')', 'story', '.', 'just', 'as', 'you', 'were', 'getting', 'into', 'it', ',', 'it', 'ended', '.', 'a', 'little', 'more', 'mystery', 'and', 'another', 'murder', 'would', 'have', 'been', 'great', '.', 'all', 'in', 'all', 'a', 'great', 'read', '##the', 'island', 'murder']\n",
            "Token IDs:  [1045, 5632, 2023, 2460, 1006, 2200, 2460, 1007, 2466, 1012, 2074, 2004, 2017, 2020, 2893, 2046, 2009, 1010, 2009, 3092, 1012, 1037, 2210, 2062, 6547, 1998, 2178, 4028, 2052, 2031, 2042, 2307, 1012, 2035, 1999, 2035, 1037, 2307, 3191, 10760, 2479, 4028]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJfjk6ZH9McO",
        "outputId": "1d231e23-ff75-4d59-ae0a-808e4bfb2b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        pad_to_max_length = True, \n",
        "                        max_length = 256,\n",
        "                        truncation = True,\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "\n",
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 256\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I enjoyed this short(very  short)story. Just as you were getting into it,it ended . A little more mystery and another murder would have been great . All in all a great readThe Island Murder\n",
            "Token IDs: [101, 1045, 5632, 2023, 2460, 1006, 2200, 2460, 1007, 2466, 1012, 2074, 2004, 2017, 2020, 2893, 2046, 2009, 1010, 2009, 3092, 1012, 1037, 2210, 2062, 6547, 1998, 2178, 4028, 2052, 2031, 2042, 2307, 1012, 2035, 1999, 2035, 1037, 2307, 3191, 10760, 2479, 4028, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Padding/truncating all sentences to 256 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGHpVjyy9Msi"
      },
      "source": [
        "# Use 80% for training and 10% for validation, 10% for testing.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, temp_inputs, train_labels, temp_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "\n",
        "validation_inputs, test_inputs, validation_labels, test_labels = train_test_split(temp_inputs, temp_labels, \n",
        "                                                            random_state=2018, test_size=0.5)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, temp_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "\n",
        "validation_masks, test_masks, _, _ = train_test_split(temp_masks, temp_labels,\n",
        "                                             random_state=2018, test_size=0.5)\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSHi3Voe9lg2"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "def model_classification(k):\n",
        "  # Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "  # linear classification layer on top. \n",
        "  model = BertForSequenceClassification.from_pretrained(\n",
        "      \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "      num_labels = k, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "      output_attentions = False, # Whether the model returns attentions weights.\n",
        "      output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTecIl72Be_w",
        "outputId": "3c54127b-3771-469f-dc1d-fb7ba0f8477c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fa43b4de9aaa44229ee488a969aece23",
            "168e913bce044bd283542df0714290b4",
            "9eb4553b14144ec389304658ba2749c2",
            "e7ccf7e1035f450dbf4a6e959354bb3f",
            "ae1e6d0c3d18479ea17eb678054f7b0d",
            "8d6cf496c2654dab8646ba27d6c5a1dd",
            "33d8db7e47f346938e65d2c22fe06473",
            "ff4acbb004a84a08a7b2f5fcfebdfeae",
            "63ea1e647b89438eafa0dd19f94c34e1",
            "3de1d31cfa09476fb05f4610df94339f",
            "04dca8ef74ae4088b131478584777cf7",
            "fb74a3939ab04f049010ea034583ad44",
            "0f3cd2d2b04e47fdac16cdc202dc6a79",
            "e70a7aecd0984a969c43a24639829d92",
            "76e2cbeddd1c4e6481881651f44ca8b2",
            "9b3f128a2c894578b7ad977ff9c01541"
          ]
        }
      },
      "source": [
        "model = model_classification(3)\n",
        "  # Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa43b4de9aaa44229ee488a969aece23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63ea1e647b89438eafa0dd19f94c34e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv2DJbw99Mw_"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4C4A7Ur_I62"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK1n0qtJ_I9s"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1H4A9bb_JBf"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFky6tSI_I5b",
        "outputId": "44ebad4e-3bc2-4b5b-ead8-6a220ba3b53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "import random\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:00:56.\n",
            "  Batch    80  of    215.    Elapsed: 0:01:55.\n",
            "  Batch   120  of    215.    Elapsed: 0:02:54.\n",
            "  Batch   160  of    215.    Elapsed: 0:03:53.\n",
            "  Batch   200  of    215.    Elapsed: 0:04:53.\n",
            "\n",
            "  Average training loss: 0.71\n",
            "  Training epcoh took: 0:05:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    215.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    215.    Elapsed: 0:02:58.\n",
            "  Batch   160  of    215.    Elapsed: 0:03:58.\n",
            "  Batch   200  of    215.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:05:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    215.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    215.    Elapsed: 0:02:58.\n",
            "  Batch   160  of    215.    Elapsed: 0:03:57.\n",
            "  Batch   200  of    215.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:05:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    215.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    215.    Elapsed: 0:02:59.\n",
            "  Batch   160  of    215.    Elapsed: 0:03:58.\n",
            "  Batch   200  of    215.    Elapsed: 0:04:58.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:05:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    215.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    215.    Elapsed: 0:02:58.\n",
            "  Batch   160  of    215.    Elapsed: 0:03:58.\n",
            "  Batch   200  of    215.    Elapsed: 0:04:57.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:05:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HqeFRl_CPvL",
        "outputId": "f5c9c05f-7742-4ca4-c8e8-0ca74a00b104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2N4fSMGCQLT",
        "outputId": "a3c1fd08-75d0-4f94-b0c2-1f72e6790be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 859 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARrOw49_CSeW",
        "outputId": "603e6840-0778-436d-c389-3c7f8136f6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_labels = []\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 3-column ndarray (two columns for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  pred_labels.append(pred_labels_i)\n",
        "\n",
        "true_label = 0\n",
        "for i in range(len(pred_labels)):\n",
        "  for j in range(len(pred_labels[i])):\n",
        "    if pred_labels[i][j] == true_labels[i][j]:\n",
        "      true_label += 1 \n",
        "\n",
        "print('The test accuracy is {}%'.format(round(true_label/len(test_inputs),4)*100)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test accuracy is 76.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e9ma2qKEnkw"
      },
      "source": [
        "# Reference:\n",
        "\n",
        "# Transfer Learning for NLP: Fine-Tuning BERT for Text Classification\n",
        "# https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
        "\n",
        "# Multi Class Text Classification With Deep Learning Using BERT\n",
        "# https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613\n",
        "\n",
        "# A Visual Guide to Using BERT for the First Time\n",
        "# http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
        "\n",
        "# Tokenizers: How machines read \n",
        "# https://blog.floydhub.com/tokenization-nlp/\n",
        "\n",
        "# 3 subword algorithms help to improve your NLP model performance\n",
        "# https://medium.com/@makcedward/how-subword-helps-on-your-nlp-model-83dd1b836f46\n",
        "\n",
        "# Text preprocessing for BERT\n",
        "# https://www.kaggle.com/c/google-quest-challenge/discussion/127881\n",
        "\n",
        "# The Illustrated Transformer\n",
        "# http://jalammar.github.io/illustrated-transformer/\n",
        "\n",
        "# BERT Fine-Tuning Sentence Classification\n",
        "# https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=nSU7yERLP_66\n",
        "\n",
        "# BERT Explained – A list of Frequently Asked Questions\n",
        "# https://yashuseth.blog/2019/06/12/bert-explained-faqs-understand-bert-working/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gieNLf04ueS8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}